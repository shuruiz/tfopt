{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random \n",
    "from network import Network\n",
    "from sklearn.utils.extmath import softmax\n",
    "\n",
    "def _create_population(size=100):\n",
    "    \"\"\"\n",
    "    size: population size, number of chromesomes \n",
    "\n",
    "    return population, which is a list of random created network graphs\n",
    "    \"\"\"\n",
    "    population = []\n",
    "    for _ in range(size):\n",
    "        nn = Network()\n",
    "        nn.random_initialize() #  shape \n",
    "        population.append(nn)\n",
    "    return population\n",
    "\n",
    "def encode(weights, bias):\n",
    "    \"\"\"\n",
    "    encode genes to a chromosome\n",
    "    \"\"\"\n",
    "    gene=[]\n",
    "    assert len(weights)==len(bias), \"length of weiths not equal to length of bias\"\n",
    "    n_layers = len(bias)\n",
    "    for i in range(n_layers):\n",
    "        gene.extend(weights[k].flatten())\n",
    "        gene.append(bias[i])\n",
    "    return gene \n",
    "         \n",
    "\n",
    "    \n",
    "def decode(gene,structure):\n",
    "    \"\"\"\n",
    "    decoed genes of a chromosome\n",
    "    structure is the network structure, e.g.[num_inputs, 10,20,30]\n",
    "    \"\"\"\n",
    "    Weights ={}\n",
    "    Bias={}\n",
    "    \n",
    "    gene_index = 0\n",
    "    for index in range(len(structure)):\n",
    "        weight=np.zeros((structure[index],structure[index+1]))\n",
    "        bias =[]\n",
    "        for i in range(structure[index]):\n",
    "            for j in range(structure[index+1]):\n",
    "                weight[i][j] = gene[gene_index]\n",
    "                gene_index+=1\n",
    "        bias.append(gene[gene_index])\n",
    "        gene_index+=1\n",
    "        Weights[index] = weight\n",
    "        Bias[index] = bias\n",
    "        \n",
    "    return Weights, Bias\n",
    "           \n",
    "    \n",
    "def mutate(chro, mutation_rate):\n",
    "    #for each gene, it can decide to change itself to the mean of its nearby genes or not\n",
    "    new_chro = []\n",
    "        \n",
    "    for i in range(len(chro)-1):\n",
    "        xx = (chro[i]+chro[i-1]+chro[i+1] )/3\n",
    "        new_chro.append(xx)\n",
    "    return new_chro\n",
    "    \n",
    "\n",
    "def crossover(chro1, chro2):\n",
    "    # create a random crossover point\n",
    "    assert len(chro1) ==len(chro2), \"chromosome not the same length\"\n",
    "    index = np.random.randint(low=1, high=len(chro1))\n",
    "    temp1 = chro1[index:]\n",
    "    temp3 = chro1[:index]\n",
    "    temp2 = chro2[:index]\n",
    "    temp4 = chro2[index:]\n",
    "    #random combine half of chro1 genes and half of chro2 genes below\n",
    "    rd = np.random.choice([1,2,3,4])\n",
    "    if rd ==1:\n",
    "        new_chro = temp1.extend(temp2)\n",
    "    if rd ==2:\n",
    "        new_chro = temp1.extend(temp4)\n",
    "    if rd ==3:\n",
    "        new_chro = temp3.extend(temp2)\n",
    "    if rd==4:\n",
    "        new_chro = temp3.extend(temp4)\n",
    "    return new_chro\n",
    "    \n",
    "\n",
    "def selection(parents,pop):\n",
    "    chirldren=[] #get two chirldren\n",
    "    chrome={}\n",
    "    for i in range(len(parents)):\n",
    "        parent_id = parents[i][0]\n",
    "        nn=pop[parent_id]\n",
    "        weight = nn.getWeights()\n",
    "        bias = nn.getBias()\n",
    "        gene = encode(weights, bias)\n",
    "        chrome[i] = gene\n",
    "    \n",
    "    chirldren[0] = crossover(chrome[0], chrome[1])\n",
    "    chirldren[1] = crossover(chrome[2],chrome[3])\n",
    "    \n",
    "    return chirldren\n",
    "           \n",
    "         \n",
    "def GeneticAlgorithmTrainner(X,y, nn_structure, episodes = 10000, mutation_rate = 0.1):\n",
    "    # first generation \n",
    "    pop = _create_population()\n",
    "    fit_score= []\n",
    "    \n",
    "    avg_fit_scores=[]\n",
    "    for i in range(len(pop)):\n",
    "        nn = pop[i]\n",
    "        score = fitness(nn,X,y)\n",
    "        fit_score.append([i,score])\n",
    "    \n",
    "    fit_score=np.array(fit_score)\n",
    "    fit_score[np.argsort(fit_score[:, 1])]\n",
    "    fit_score=np.flip(fit_score,0)\n",
    "    \n",
    "    len_pop=[]\n",
    "    \n",
    "    # select the nn with hightest 4 fitness scores\n",
    "    for epi in range(episodes):\n",
    "        len_pop.append(len(pop))\n",
    "        if len_pop[epi] ==len_pop[epi-1]:\n",
    "            #converged \n",
    "            print(\"converged\")\n",
    "            break \n",
    "        \n",
    "        avg_fit_scores.append(mean(fit_score[:,1]))\n",
    "        \n",
    "        luckyest = fit_score[:4]\n",
    "        \n",
    "        #remove two worst case\n",
    "#         worst2= fit_score[-2:]\n",
    "#         for s in worst2:\n",
    "#             del pop[s[0]]\n",
    "        \n",
    "        offspring = selection(luckyest, pop)\n",
    "        \n",
    "        for kid in offspring:\n",
    "            #mutation\n",
    "            p = np.random.random_sample()\n",
    "            if p <mutation_rate:\n",
    "                kid = mutate(kid, mutation_rate )\n",
    "            Weights, Bias = decode(kid)\n",
    "            nn = Network()\n",
    "            nn.setWeights(Weights)\n",
    "            nn.setBias(Bias)\n",
    "            pop.append(nn)\n",
    "        fit_score= []\n",
    "        #calculate new fitness score \n",
    "        for i in range(len(pop)):\n",
    "            nn = pop[i]\n",
    "            score = fitness(nn,X,y)\n",
    "            fit_score.append([i,score])\n",
    "        fit_score=np.array(fit_score)\n",
    "        fit_score[np.argsort(fit_score[:, 1])]\n",
    "        fit_score=np.flip(fit_score,0)\n",
    "        \n",
    "        len_pop = len(population)\n",
    "        if len_pop\n",
    "    return best_fit_scores\n",
    "        \n",
    "def fitness(nn, X, y):\n",
    "    ## 1/ cross_entropy \n",
    "    W = nn.getWeights()  #W is a dict, W[i] = [[n_layer_nodes, n-1_layer_nodes]]\n",
    "    b = nn.getBias() # b is a dict, b[i] = [bias of layer n]\n",
    "    z=[]\n",
    "    a = []\n",
    "    probs = []\n",
    "    n_layer = len(W)\n",
    "    \n",
    "    for i in range(n_layer):\n",
    "        if i ==0: \n",
    "            z = X.dot(W[i])+b[i]\n",
    "            a = np.tanh(z)\n",
    "        elif i< n_layer-1:\n",
    "            z = a.dot(W[i])+b[i]\n",
    "            a = np.tanh(z)\n",
    "        else: # softmax\n",
    "            z = a.dot(W[i])+b[i]\n",
    "            probs = softmax(z)\n",
    "    # use softmax to calculate cross entropy below:\n",
    "    \n",
    "    m = y.shape[0]\n",
    "    log_likelihood = -np.log(probs[range(m),y])\n",
    "    loss = np.sum(log_likelihood) / m\n",
    "    fit = 1/loss\n",
    "    return fit\n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14.46   14.35    0.8818 ...  2.802   5.044   1.    ]\n",
      " [11.23   12.88    0.8511 ...  4.325   5.003   3.    ]\n",
      " [19.51   16.71    0.878  ...  2.962   6.185   2.    ]\n",
      " ...\n",
      " [12.19   13.2     0.8783 ...  3.631   4.87    3.    ]\n",
      " [14.79   14.52    0.8819 ...  2.704   5.111   1.    ]\n",
      " [14.43   14.4     0.8751 ...  3.975   5.144   1.    ]]\n"
     ]
    }
   ],
   "source": [
    "#load data below\n",
    "\n",
    "with open('seeds_dataset.txt', 'r') as f:\n",
    "    x = f.readlines()\n",
    "data=[]\n",
    "\n",
    "for line in x:\n",
    "    temp=[]\n",
    "    temp.append(line.strip().split())\n",
    "    l = []\n",
    "    \n",
    "    for ele in temp[0]:\n",
    "        l.append(float(ele))\n",
    "    data.append(l)\n",
    "#     print(l)\n",
    "data = np.array(data)\n",
    "np.random.shuffle(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 7)\n",
      "(1, 42)\n"
     ]
    }
   ],
   "source": [
    "train_X = []\n",
    "train_y = []\n",
    "test_X=[]\n",
    "test_y=[]\n",
    "len_data = len(data)\n",
    "train_data = data[:int(len_data*0.8)]\n",
    "test_data = data[int(len_data*0.8):]\n",
    "train_X = np.array(train_data[:, [column for column in range(len(train_data[0])-1)]])\n",
    "test_X  = np.array(test_data[:, [column for column in range(len(train_data[0])-1)]])\n",
    "train_y = np.array([train_data[:,len(train_data[0])-1 ]])\n",
    "test_y = np.array([test_data[:,len(train_data[0])-1 ]])\n",
    "\n",
    "print(train_X.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "fit_data = GeneticAlgorithmTrainner(train_X,train_y, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
