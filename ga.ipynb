{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random \n",
    "from network import Network\n",
    "from sklearn.utils.extmath import softmax\n",
    "from statistics import mean\n",
    "\n",
    "def _create_population(nn_sturcture, size=100):\n",
    "    \"\"\"\n",
    "    size: population size, number of chromesomes \n",
    "\n",
    "    return population, which is a list of random created network graphs\n",
    "    \"\"\"\n",
    "    population = []\n",
    "    for _ in range(size):\n",
    "        nn = Network(nn_sturcture)\n",
    "        population.append(nn)\n",
    "#         print(\"population id\", _)\n",
    "    return population\n",
    "\n",
    "def encode(weights, bias):\n",
    "    \"\"\"\n",
    "    encode genes to a chromosome\n",
    "    \"\"\"\n",
    "    gene=[]\n",
    "#     assert len(weights)==len(bias), \"length of weiths not equal to length of bias\"\n",
    "    n_layers = len(bias)\n",
    "    for i in range(n_layers):\n",
    "        gene.extend(weights[i].flatten())\n",
    "        gene.extend(bias[i].flatten())\n",
    "    return gene \n",
    "         \n",
    "def decode(gene,structure):\n",
    "    \"\"\"\n",
    "    decoed genes of a chromosome\n",
    "    structure is the network structure, e.g.\n",
    "    structure = [dim_input[,],5,10,n_classes]\n",
    "    \"\"\"\n",
    "    Weights ={}\n",
    "    Bias={}\n",
    "    \n",
    "    gene_index = 0\n",
    "    input_dim = structure[0][1]\n",
    "    input_num = structure[0][0]\n",
    "    \n",
    "    w_stuct = [input_dim] #.extend(structure[1:])\n",
    "    \n",
    "    w_stuct.extend(structure[1:])\n",
    "#     print(\"weights structure\", w_stuct)\n",
    "    for index in range(len(w_stuct)-1):\n",
    "        weight = np.zeros((w_stuct[index],w_stuct[index+1]))\n",
    "        bias=[]\n",
    "        \n",
    "        for i in range(w_stuct[index]):\n",
    "            for j in range(w_stuct[index+1]):\n",
    "                weight[i][j] = gene[gene_index]\n",
    "                gene_index+=1\n",
    "                \n",
    "        bias=np.array(gene[gene_index:gene_index+input_num*w_stuct[index+1]])\n",
    "        bias = np.reshape(bias,(input_num, w_stuct[index+1]))\n",
    "        gene_index+= input_num*w_stuct[index+1]\n",
    "        Weights[index] = weight\n",
    "        Bias[index] = bias\n",
    "    print(\"w shape\", weight.shape, \"bias shape\", bias.shape)\n",
    "        \n",
    "    return Weights, Bias\n",
    "           \n",
    "    \n",
    "def mutate(chro, mutation_rate):\n",
    "    #for each gene, it can decide to change itself to the mean of its nearby genes or not\n",
    "    new_chro = []\n",
    "        \n",
    "    for i in range(len(chro)-1):\n",
    "        xx = (chro[i]+chro[i-1]+chro[i+1] )/3\n",
    "        new_chro.append(xx)\n",
    "    return new_chro\n",
    "    \n",
    "\n",
    "def crossover(chro1, chro2):\n",
    "    # create a random crossover point\n",
    "    assert len(chro1) ==len(chro2), \"chromosome not the same length\"\n",
    "    index = np.random.randint(low=1, high=len(chro1))\n",
    "    print(\"index\", index)\n",
    "    temp1 = chro1[index:]\n",
    "    temp3 = chro1[:index]\n",
    "    temp2 = chro2[:index]\n",
    "    temp4 = chro2[index:]\n",
    "    \n",
    "#     print(\"temp1\",temp1)\n",
    "    #random combine half of chro1 genes and half of chro2 genes below\n",
    "    rd = np.random.choice([1,2,3,4])\n",
    "#     print(\"rd\", rd)\n",
    "    new_chro=[]\n",
    "    \n",
    "    if rd ==1:\n",
    "        new_chro = temp1+temp2\n",
    "#         print(new_chro)\n",
    "    if rd ==2:\n",
    "        new_chro = temp2+temp1\n",
    "    if rd ==3:\n",
    "        new_chro = temp3+temp4\n",
    "    if rd==4:\n",
    "        new_chro = temp4+temp3\n",
    "    \n",
    "    temp1,temp2,temp3,temp4=[],[],[],[]\n",
    "        \n",
    "#     print(\"new chro\", len(new_chro), len(chro1), len(chro2))\n",
    "    return new_chro\n",
    "    \n",
    "\n",
    "def selection(parents,pop):\n",
    "    chirldren=[[],[]] #get two chirldren\n",
    "    chrome={}\n",
    "#     print(\"length parents\", len(parents))\n",
    "    for i in range(len(parents)):\n",
    "        parent_id = parents[i][0]\n",
    "        nn=pop[parent_id]\n",
    "        weights = nn.getWeights()\n",
    "        bias = nn.getBias()\n",
    "        gene = encode(weights, bias)\n",
    "        chrome[i] = gene\n",
    "#     print(\"chrome 1\", chrome[1])\n",
    "    chirldren[0] = crossover(chrome[0], chrome[1])\n",
    "    chirldren[1] = crossover(chrome[2],chrome[3])\n",
    "    \n",
    "#     print(\"chirldren\", chirldren)\n",
    "    \n",
    "    return chirldren\n",
    "           \n",
    "         \n",
    "def GeneticAlgorithmTrainner(X,y, nn_structure, episodes = 10000, mutation_rate = 0.1):\n",
    "    # first generation \n",
    "    pop = _create_population(nn_structure)\n",
    "    fit_score= []\n",
    "    \n",
    "    avg_fit_scores=[]\n",
    "    for i in range(len(pop)):\n",
    "        nn = pop[i]\n",
    "        score = fitness(nn,X,y)\n",
    "        fit_score.append([i,score])\n",
    "    \n",
    "    \n",
    "    fit_score=np.array(fit_score)\n",
    "    fit_score.sort(axis=0)\n",
    "    temp_ = []\n",
    "    fit_score =np.flip(fit_score,0)\n",
    "    for ele in fit_score:\n",
    "        temp_.append([int(ele[0]),ele[1]])\n",
    "#     print(\"score\",temp_)\n",
    "    fit_score = temp_\n",
    "#     print(\"fit score\", fit_score)\n",
    "    \n",
    "    len_pop=[]\n",
    "    \n",
    "    # select the nn with hightest 4 fitness scores\n",
    "    for epi in range(episodes):\n",
    "        \n",
    "        sc = np.sum(fit_score,axis=0)[1]/len(fit_score)\n",
    "        avg_fit_scores.append(sc)\n",
    "        print(\"fitness score\",  sc)\n",
    "        luckyest = fit_score[:4]\n",
    "#         print(\"luck 4\",luckyest)\n",
    "        \n",
    "        #remove two worst case\n",
    "#         worst2= fit_score[-2:]\n",
    "#         for s in worst2:\n",
    "#             del pop[s[0]]\n",
    "        offspring = selection(luckyest, pop)\n",
    "        \n",
    "        for kid in offspring:\n",
    "            #mutation\n",
    "#             print(\"kid chrom\", kid)\n",
    "            p = np.random.random_sample()\n",
    "            if p <mutation_rate:\n",
    "                kid = mutate(kid, mutation_rate )\n",
    "            Weights, Bias = decode(kid,structure)\n",
    "            nn = Network(nn_structure)\n",
    "            nn.setWeights(Weights)\n",
    "            nn.setBias(Bias)\n",
    "            pop.append(nn)\n",
    "        fit_score= []\n",
    "#         len_pop.append(len(pop))\n",
    "        \n",
    "#         if len_pop[epi] ==len_pop[epi-1]:\n",
    "#             #converged \n",
    "#             print(\"converged\")\n",
    "#             break \n",
    "        #calculate new fitness score \n",
    "    \n",
    "        print(\"here\")\n",
    "        for i in range(len(pop)):\n",
    "            nn = pop[i]\n",
    "            score = fitness(nn,X,y)\n",
    "            fit_score.append([i,score])\n",
    "            \n",
    "        fit_score=np.array(fit_score)\n",
    "        fit_score.sort(axis=0)\n",
    "        \n",
    "        score = []\n",
    "        fit_score =np.flip(fit_score,0)\n",
    "        for ele in fit_score:\n",
    "            score.append([int(ele[0]),ele[1]])\n",
    "        fit_score = score\n",
    "        print(\"episodes end\", epi)\n",
    "    return avg_fit_scores\n",
    "        \n",
    "def fitness(nn, X, y):\n",
    "    ## 1/ cross_entropy \n",
    "    W = nn.getWeights()  #W is a dict, W[i] = [[n_layer_nodes, n-1_layer_nodes]]\n",
    "    b = nn.getBias() # b is a dict, b[i] = [bias of layer n]\n",
    "    z=[]\n",
    "    a = []\n",
    "    probs = []\n",
    "    n_layer = len(W)\n",
    "    \n",
    "\n",
    "    \n",
    "    for i in range(n_layer):\n",
    "#         print(\"x shape\", X.shape, \"y shape\", y.shape)\n",
    "#         print(\"w shape\", W[i].shape, \"bshape\", b[i].shape)\n",
    "#         print(\"w shape\", W[i].shape, \"b shape\", b[i].shape)\n",
    "        if i ==0: \n",
    "            z = np.matmul(X, W[i])+b[i]\n",
    "            a = np.tanh(z)\n",
    "        elif i< n_layer-1:\n",
    "            z = np.matmul(a,W[i])+b[i]\n",
    "            a = np.tanh(z)\n",
    "        else: # softmax\n",
    "            z = np.matmul(a, W[i])+b[i]\n",
    "            probs = softmax(z)\n",
    "    probs = np.array(probs)\n",
    "#     print(\"probs shape\", probs.shape)\n",
    "    # use softmax to calculate cross entropy below:\n",
    "    ones = np.ones([1, len(y[0])])\n",
    "    m = len(y[0])\n",
    "    loss = -(1.0/m) * np.sum((np.dot(y, np.log(probs)) + np.dot(ones-y, np.log(1-probs))))\n",
    "#     log_likelihood = -np.log(probs[range(m),y])\n",
    "#     loss = np.sum(log_likelihood) / m\n",
    "    fit = 1/loss\n",
    "    return fit\n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20.97   17.25    0.8859 ...  4.677   6.316   2.    ]\n",
      " [12.74   13.67    0.8564 ...  2.504   4.869   1.    ]\n",
      " [18.14   16.12    0.8772 ...  3.619   6.011   2.    ]\n",
      " ...\n",
      " [17.12   15.55    0.8892 ...  2.858   5.746   2.    ]\n",
      " [14.33   14.28    0.8831 ...  3.328   5.224   1.    ]\n",
      " [11.75   13.52    0.8082 ...  4.378   5.31    3.    ]]\n"
     ]
    }
   ],
   "source": [
    "#load data below\n",
    "\n",
    "with open('seeds_dataset.txt', 'r') as f:\n",
    "    x = f.readlines()\n",
    "data=[]\n",
    "\n",
    "for line in x:\n",
    "    temp=[]\n",
    "    temp.append(line.strip().split())\n",
    "    l = []\n",
    "    \n",
    "    for ele in temp[0]:\n",
    "        l.append(float(ele))\n",
    "    data.append(l)\n",
    "#     print(l)\n",
    "data = np.array(data)\n",
    "np.random.shuffle(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 7)\n",
      "(1, 42)\n"
     ]
    }
   ],
   "source": [
    "train_X = []\n",
    "train_y = []\n",
    "test_X=[]\n",
    "test_y=[]\n",
    "len_data = len(data)\n",
    "train_data = data[:int(len_data*0.8)]\n",
    "test_data = data[int(len_data*0.8):]\n",
    "train_X = np.array(train_data[:, [column for column in range(len(train_data[0])-1)]])\n",
    "test_X  = np.array(test_data[:, [column for column in range(len(train_data[0])-1)]])\n",
    "train_y = np.array([train_data[:,len(train_data[0])-1 ]])\n",
    "test_y = np.array([test_data[:,len(train_data[0])-1 ]])\n",
    "\n",
    "print(train_X.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20.97   17.25    0.8859  6.563   3.991   4.677   6.316 ]\n",
      " [12.74   13.67    0.8564  5.395   2.956   2.504   4.869 ]\n",
      " [18.14   16.12    0.8772  6.059   3.563   3.619   6.011 ]\n",
      " [10.79   12.93    0.8107  5.317   2.648   5.462   5.194 ]\n",
      " [18.94   16.49    0.875   6.445   3.639   5.064   6.362 ]\n",
      " [12.76   13.38    0.8964  5.073   3.155   2.828   4.83  ]\n",
      " [13.34   13.95    0.862   5.389   3.074   5.995   5.307 ]\n",
      " [10.8    12.57    0.859   4.981   2.821   4.773   5.063 ]\n",
      " [11.83   13.23    0.8496  5.263   2.84    5.195   5.307 ]\n",
      " [11.48   13.05    0.8473  5.18    2.758   5.876   5.002 ]]\n"
     ]
    }
   ],
   "source": [
    "print(train_X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 7)\n"
     ]
    }
   ],
   "source": [
    "n_classes = 3\n",
    "n_examples = len(train_X)\n",
    "dim_input = train_X.shape\n",
    "print(dim_input)\n",
    "structure = [dim_input,5,10,n_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitness score 0.07794583397144715\n",
      "index 624\n",
      "index 2778\n",
      "w shape (10, 3) bias shape (168, 3)\n",
      "w shape (10, 3) bias shape (168, 3)\n",
      "here\n",
      "episodes end 0\n",
      "fitness score 0.07809676010185584\n",
      "index 58\n",
      "index 1425\n",
      "w shape (10, 3) bias shape (168, 3)\n",
      "w shape (10, 3) bias shape (168, 3)\n",
      "here\n",
      "episodes end 1\n",
      "fitness score 0.07815847238769448\n",
      "index 860\n",
      "index 1891\n",
      "w shape (10, 3) bias shape (168, 3)\n",
      "w shape (10, 3) bias shape (168, 3)\n",
      "here\n",
      "episodes end 2\n",
      "fitness score 0.0782565048784615\n",
      "index 1358\n",
      "index 472\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 503 into shape (168,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e083f48fa51a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGeneticAlgorithmTrainner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-7e1882c0234a>\u001b[0m in \u001b[0;36mGeneticAlgorithmTrainner\u001b[0;34m(X, y, nn_structure, episodes, mutation_rate)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mmutation_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0mkid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutation_rate\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mWeights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetWeights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWeights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-7e1882c0234a>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(gene, structure)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgene\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgene_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mgene_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0minput_num\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw_stuct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_stuct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mgene_index\u001b[0m\u001b[0;34m+=\u001b[0m \u001b[0minput_num\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw_stuct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mWeights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sara/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    255\u001b[0m            [5, 6]])\n\u001b[1;32m    256\u001b[0m     \"\"\"\n\u001b[0;32m--> 257\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sara/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 503 into shape (168,3)"
     ]
    }
   ],
   "source": [
    "fit_data = GeneticAlgorithmTrainner(train_X,train_y,structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
